{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cyclegan-landmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safwanp314/cari-net/blob/master/cyclegan_landmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiSU6Igfbq78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c9d1ee-7020-446e-fca4-3ed667e3de87"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLHjAGhgbwu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorflow-addons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKqhu-IxR7aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/lsaiml/CaVINet.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCdycMDvboN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow_addons.layers import InstanceNormalization, GroupNormalization\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vQPWKbItXtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuUTrIlWSKSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import dlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vKKAaRrSST3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d028ae69-8f64-491b-87e5-994f2a648759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpC3uPpaSNP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('/content/drive/My Drive/Deep Learning/shape_predictor_68_face_landmarks.dat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYpCdmT_SyrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_files(directory, extension):\n",
        "  try:\n",
        "    file_list = []\n",
        "    for file in os.listdir(directory):\n",
        "      if file.endswith('.' + extension):\n",
        "        file_list.append(os.path.abspath(directory + '/' + file))\n",
        "      elif (os.path.isdir(directory + '/' + file)):\n",
        "        file_list.extend(find_files(directory + '/' + file, extension))\n",
        "    return file_list\n",
        "  except:\n",
        "    print('directory not found')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5wP8vHUv1Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_path = './CaVINet/CaVI_Dataset'\n",
        "ext = 'jpg'\n",
        "input_image_files = find_files(input_path, ext)\n",
        "input_image_files.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk38ISnzbR9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_dim_landmark = 68\n",
        "\n",
        "n_dim_landmark_pca = 32\n",
        "\n",
        "n_dim_disc = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Is8djVESgIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rect_to_bb(rect):\n",
        "\t# take a bounding predicted by dlib and convert it\n",
        "\t# to the format (x, y, w, h) as we would normally do\n",
        "\t# with OpenCV\n",
        "\tx = rect.left()\n",
        "\ty = rect.top()\n",
        "\tw = rect.right() - x\n",
        "\th = rect.bottom() - y\n",
        "\t# return a tuple of (x, y, w, h)\n",
        "\treturn (x, y, w, h)\n",
        "\n",
        "def to_numpy(shape, dtype=\"int\"):\n",
        "\t# initialize the list of (x, y)-coordinates\n",
        "\tcoords = np.zeros((n_dim_landmark, 2), dtype=dtype)\n",
        "\t# loop over the 68 facial landmarks and convert them\n",
        "\t# to a 2-tuple of (x, y)-coordinates\n",
        "\tfor i in range(0, n_dim_landmark):\n",
        "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "\t# return the list of (x, y)-coordinates\n",
        "\treturn coords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps5AN9BSStDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c46459fd-7a0b-4c4e-fc99-39f75c5c141d"
      },
      "source": [
        "landmarks = []\n",
        "dataset = {}\n",
        "\n",
        "num_of_files = len(input_image_files)\n",
        "print('number of files', num_of_files)\n",
        "for idx, file in enumerate(input_image_files):\n",
        "\n",
        "  name_split = file.split('/')\n",
        "  image_type = name_split[-3]\n",
        "  personality = name_split[-2]\n",
        "\n",
        "  # load the input image, resize it, and convert it to grayscale\n",
        "  image = cv2.imread(file)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # detect faces in the grayscale image\n",
        "  rects = detector(gray, 1)\n",
        "  # loop over the face detections\n",
        "  for (i, rect) in enumerate(rects):\n",
        "    # determine the facial landmarks for the face region, then\n",
        "    # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
        "    shape = predictor(gray, rect)\n",
        "    shape = to_numpy(shape)\n",
        "  landmarks.append(shape)\n",
        "\n",
        "  if (not personality in dataset):\n",
        "    dataset[personality] = {}\n",
        "  if (not image_type in dataset[personality]):\n",
        "    dataset[personality][image_type] = []\n",
        "  dataset[personality][image_type].append(shape)\n",
        "\n",
        "  sys.stdout.write('\\r%.2f %%' % ((idx + 1) * 100.0 / num_of_files))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of files 12379\n",
            "100.00 %"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGzTNBK80bKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "landmarks = np.array(landmarks).reshape((len(landmarks), n_dim_landmark * 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBH1ghEZULYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "faf0aaa5-c2ff-46cc-da28-8626e8829743"
      },
      "source": [
        "pca = PCA(n_components=n_dim_landmark_pca)\n",
        "pca.fit(landmarks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=32, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsYDiW_TI5jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(n_dim_landmark_pca=n_dim_landmark_pca):\n",
        "  # Landmark generator architecture \n",
        "  inp = Input(shape=(n_dim_landmark_pca))\n",
        "  x = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(inp)\n",
        "  x = Dropout(0.1)(x)   \n",
        "\n",
        "  x = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "\n",
        "  x = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "\n",
        "  x = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "      \n",
        "  enc_landmarks = Dense(n_dim_landmark_pca, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "  \n",
        "  return Model(inp, enc_landmarks, name='landmark_generator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0VpCapWdbnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(n_dim_landmark_pca=n_dim_landmark_pca, n_dim_disc=n_dim_disc):\n",
        "  # Landmark discriminator architecture \n",
        "  inp = Input(shape=(n_dim_landmark_pca))\n",
        "  \n",
        "  x = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inp)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "\n",
        "  x = Dense(32, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "\n",
        "  x = Dense(16, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='relu')(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dropout(0.1)(x)   \n",
        "      \n",
        "  enc_landmarks = Dense(n_dim_disc, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4), activation='sigmoid')(x)\n",
        "  \n",
        "  return Model(inp, enc_landmarks, name='landmark_discriminator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qVQT301cz_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_g = build_generator()\n",
        "generator_f = build_generator()\n",
        "\n",
        "discriminator_x = build_discriminator()\n",
        "discriminator_y = build_discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d40_F7nPjrbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_obj = BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7-ENRvcjmGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(generated):\n",
        "  return loss_obj(tf.ones_like(generated), generated)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onCNKAU7kBfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real, generated):\n",
        "  real_loss = loss_obj(tf.ones_like(real), real)\n",
        "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "  return total_disc_loss * 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXVf_sx7jzVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cycle_loss(real_image, cycled_image):\n",
        "  return tf.reduce_mean(tf.abs(real_image - cycled_image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OoAm_cuqGKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_loss(real_image, same_image):\n",
        "  return tf.reduce_mean(tf.abs(real_image - same_image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vBTotpNtOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_g_optimizer = Adam(2e-4, beta_1=0.5)\n",
        "generator_f_optimizer = Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "discriminator_x_optimizer = Adam(2e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VyXKb4NsuYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "  # persistent is set to True because the tape is used more than\n",
        "  # once to calculate the gradients.\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Generator G translates X -> Y\n",
        "    # Generator F translates Y -> X.\n",
        "    \n",
        "    fake_y = generator_g(real_x, training=True)\n",
        "    cycled_x = generator_f(fake_y, training=True)\n",
        "\n",
        "    fake_x = generator_f(real_y, training=True)\n",
        "    cycled_y = generator_g(fake_x, training=True)\n",
        "\n",
        "    # same_x and same_y are used for identity loss.\n",
        "    same_x = generator_f(real_x, training=True)\n",
        "    same_y = generator_g(real_y, training=True)\n",
        "\n",
        "    disc_real_x = discriminator_x(real_x, training=True)\n",
        "    disc_real_y = discriminator_y(real_y, training=True)\n",
        "\n",
        "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
        "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
        "\n",
        "    # calculate the loss\n",
        "    gen_g_loss = generator_loss(disc_fake_y)\n",
        "    gen_f_loss = generator_loss(disc_fake_x)\n",
        "    \n",
        "    total_cycle_loss = cycle_loss(real_x, cycled_x) + cycle_loss(real_y, cycled_y)\n",
        "    \n",
        "    # Total generator loss = adversarial loss + cycle loss\n",
        "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
        "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "  \n",
        "  # Calculate the gradients for generator and discriminator\n",
        "  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
        "  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
        "  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
        "  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
        "  \n",
        "  # Apply the gradients to the optimizer\n",
        "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
        "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
        "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb7MQc4PKy2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.keys()[0:10]\n",
        "\n",
        "for idx, personality in enumerate(train_dataset):\n",
        "  \n",
        "  real = dataset[personality]['Real']\n",
        "  caricature = dataset[personality]['Caricature']\n",
        "\n",
        "  n_real = len(real)\n",
        "  n_caricature = len(caricature)\n",
        "  n_combination = max(int(0.25 * n_real * n_caricature), 2)\n",
        "  \n",
        "  for i in range(n_combination):\n",
        "    image_x = choice(real).reshape((1, n_dim_landmark * 2))\n",
        "    image_x = pca.transform(image_x).astype('float32')\n",
        "    \n",
        "    image_y = choice(caricature).reshape((1, n_dim_landmark * 2))\n",
        "    image_y = pca.transform(image_y).astype('float32')\n",
        "\n",
        "    train_step(image_x, image_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpmFy7JBVFWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}